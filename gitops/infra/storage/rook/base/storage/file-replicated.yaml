apiVersion: ceph.rook.io/v1
kind: CephFilesystem
metadata:
  name: repfs
  namespace: rook-ceph
spec:
  metadataPool:
    replicated:
      size: 3
  dataPools:
    - name: replicated
      replicated:
        size: 3
  preserveFilesystemOnDelete: true
  metadataServer:
    activeCount: 1
    activeStandby: true
---
apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: rook-ceph-file
# Change "rook-ceph" provisioner prefix to match the operator namespace if needed
provisioner: rook-ceph.cephfs.csi.ceph.com
parameters:
  # clusterID is the namespace where the rook cluster is running
  # If you change this namespace, also change the namespace below where the secret namespaces are defined
  clusterID: rook-ceph

  # CephFS filesystem name into which the volume shall be created
  fsName: repfs

  # Ceph pool into which the volume shall be created
  # Required for provisionVolume: "true"
  pool: repfs-replicated

  # The secrets contain Ceph admin credentials. These are generated automatically by the operator
  # in the same namespace as the cluster.
  csi.storage.k8s.io/provisioner-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/provisioner-secret-namespace: rook-ceph
  csi.storage.k8s.io/controller-expand-secret-name: rook-csi-cephfs-provisioner
  csi.storage.k8s.io/controller-expand-secret-namespace: rook-ceph
  csi.storage.k8s.io/node-stage-secret-name: rook-csi-cephfs-node
  csi.storage.k8s.io/node-stage-secret-namespace: rook-ceph

reclaimPolicy: Delete
allowVolumeExpansion: true
#---
#apiVersion: snapshot.storage.k8s.io/v1
#kind: VolumeSnapshotClass
#metadata:
#  name: csi-cephfsplugin-snapclass
#  labels:
#    velero.io/csi-volumesnapshot-class: "true"
#provisioner: rook-ceph.cephfs.csi.ceph.com
#deletionPolicy: Delete
#parameters:
#  clusterID: rook-ceph
#  csi.storage.k8s.io/snapshotter-secret-name: rook-csi-cephfs-provisioner
#  csi.storage.k8s.io/snapshotter-secret-namespace: rook-ceph